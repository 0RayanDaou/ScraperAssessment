Notes to self:
1- Scraping is done through URL
	Ex: https://www.workplacerelations.ie/en/search/?decisions=1&q=%22Labour%22&from=4/8/2025&to=1/12/2025&body=1,3,15376
2- Ids Determined for body:
	Employment Appeals Tribunal: 2
	Equality Tribunal: 1
	Labour Count Id: 3
	Workplace Relations Commission: 15376
3- q = query to search (surround with double quotes)
3- decisions? 
4- Async requests as per documentation? 

Local Environment:
1- Downloaded and set up Git
2- Create Repo: ScraperAssessment
3- Cloned and connected to VSCode to GitHub
4- Created venv for this project
5- Downloaded the two libraries needed: scrapy and pymongo
6- Created a MongoDB Cluster (free version)
	6.1 Allowed access for all
	6.2 Username: admin
	6.3 Password: admin
	6.4 Connection String: mongodb+srv://username:<password>@scrapercluster.k435ykh.mongodb.net/?appName=ScraperCluster
	-- unnecessary, will use mongodb locally with docker

Scraper:
1- Scraper is ran through a command outside the python editor. 
2- Spider → yields Request → Scheduler → Downloader → Response → callback
3- Start project for scraper (everytime?)
  - scrapy startproject projectName
  - Create Spider within ProjectName/scraper/spiders
4- The request with relative path will be saved in scraper directory (created by engine)
5- nothing can be done without initiating scraper
6- All custom classes should be within scraper directory that includes the .cfg file

to call the scraper:
	scrapy crawl documents -a start_date=04/10/2025  -a end_date=14/11/2025 -a query=labour -a body="Labour Count,Workplace Relations 	Commission" -a partition=10
docker compose run --rm scraper scrapy crawl documents -a start_date=04/10/2025 -a end_date=14/11/2025 -a query=labour -a body="Labour Court,Workplace Relations Commission" -a partition=10

docker compose run --rm scraper -a start_date=04/10/2025 -a end_date=14/11/2025 -a query=labour -a body="Labour Court,Workplace Relations Commission" -a partition=10

Scrapy is event-driven

Docker / MinIO - https://hub.docker.com/r/bitnami/minio:
1- Create doceker-compose.yaml
  - Services used: mongo for metadata, minio for object storage, scraper (my work)
2- Create Dockerfile (no extension), steps for docker to follow
3- Create MinIO client to be able to connect and upload to MinIO
4- To Create containers and servies:
   - build containers/services: 
	docker-compose build
   - Start services: 
	docker-compose up -d

5- Testing locally needs local Mongo and MinIO so different connections.
   - Allow the code to determine at which environment we are (debug: local, docker: connections) 

When testing locally:
- http://localhost:9001/browser/landing --> to check files saved
- Since mongo used is within docker, the:
   - run in terminal:
     1- docker exec -it documents_mongo mongosh 
	##documents_mongo is container name
     2- use WorkplaceRelation_metadata
     3- db.documents_metadata.find().limit(4).pretty() 
	##documents_metadata is db name
     4- exit() to return to env

When testing through Docker:
- Open Docker
- docker-compose build --no-cache scraper 
- docker-compose up -d mongo minio
- docker compose run --rm scraper scrapy crawl documents -a start_date=01/01/2025 -a end_date=14/12/2025 -a query=labour -a body="Labour Court,Workplace Relations Commission,Equality Tribunal,Employment Appeals Tribunal" -a partition=10
  -- schedule using 

Item Example:
  {
    _id: ObjectId('693ee92dd111235465014f58'),
    Id: 'ADJ-00049193',
    date: '23/04/2025',
    description: 'Rebecca  Conlan V Forenaghts Stud Farm Limited',
    documentURL: 'https://www.workplacerelations.ie/en/cases/2025/april/adj-00049193.html',
    fileHash: '91bdab57b5dcd12b30f21e96239792623b3f72fbb644a0281097e2d7aebf548c',
    filePath: 'landing/Labour Court-Workplace Relations Commission-Equality Tribunal-Employment Appeals Tribunal_21-04-2025/ADJ-00049193.html',
    fileType: 'html',
    partition_date: '21-04-2025',
    sourceURL: 'https://www.workplacerelations.ie/en/search/?decisions=1&q=%22labour%22&from=21/04/2025&to=01/05/2025&body=15376,1,2&pageNumber=3',
    title: 'ADJ-00049193'
  }

Labour Court-Workplace Relations Commission-Equality Tribunal-Employment Appeals Tribunal_23-01-2025 --> has folder inside
Labour Court-Workplace Relations Commission-Equality Tribunal-Employment Appeals Tribunal_14-02-2025/ADE/24
Labour Court-Workplace Relations Commission-Equality Tribunal-Employment Appeals Tribunal_03-02-2025 --> has pdf inside
Code:
Custom Logger class template created from previous experience/project
Custom Helper class - hold generic functions to be used other places
Custom Exception class template created from previous experience/project
Custom Item Class - will allow the definition of metadata to be extracted. 

Set Up MongoDB:



Run to initialize Database: 
 - docker compose run --rm scraper scrapy crawl documents -a start_date=01/01/2025 -a end_date=14/12/2025 -a query=labour -a body="Labour Court,Workplace Relations Commission,Equality Tribunal,Employment Appeals Tribunal" -a partition=10
