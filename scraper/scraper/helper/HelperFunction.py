from scraper.exception.Exception import *
from scraper.logger.Logger import Logger
from datetime import datetime, timedelta
import math


class HelperFunction():
    """
    This class is used to act as a helper class, that will include functions that help all classes in this assessment - when applicable.
    It will have the below functions:
    - logAction: Uses the logger class to log actions to log file.
    - constructScrapingList: Takes as input start_date, end_date, query, body, and partition 
        to construct the list of URLs to be used tto be web scrape.  
    """

    def __init__(self, MDB_connectionString, logFileFullPath, loggerLevel):
        # Initailize Looger Class
        self.logger = Logger(logFileFullPath, 'DEBUG')
        # Map strings to Ids that are used in the search URL
        self.bodyMap = {
            "Employment Appeals Tribunal": 2,
            "Equality Tribunal": 1,
            "Labour Count": 3,
            "Workplace Relations Commission": 15376
        }

    def logAction(self, level, actionName=None, state=None, customMessage=None):
        """
        Logs an action to the log file. This encapsulates the concatenation of an
        action, state, and the custom message. The result is in the format of:
        actionName: state if customMessage is not passed.
        Other logs explicitly the custom Message

        Args:
        ---------------------
            level: The logging level. This can be one of the following values:
            - `info`: Log general information about the application.
            - `debug`: Log detailed information about the application, such as function calls and variable values.
            - `critical`: Log critical errors that prevent the application from functioning correctly.
            - `warning`: Log warnings about potential problems with the application.
            - `error`: Log errors that occur during the execution of the application.
            actionName: The name of the action that is being logged.
            state: The state of the action. This could be a success message, a failure message, or a warning message.
            customMessage: A custom message to be logged. If this argument is not specified, the message will be generated by the function.

        Returns:
        ---------------------
            None
        """

        # Get the target function for the logging level.
        if level == 'info':
            targetFunction = self.logger.logger.info
        elif level == 'debug':
            targetFunction = self.logger.logger.debug
        elif level == 'critical':
            targetFunction = self.logger.logger.critical
        elif level == 'warning':
            targetFunction = self.logger.logger.warning
        elif level == 'error':
            targetFunction = self.logger.logger.error

        # Compile the message to be logged.
        if customMessage is not None:
            compiledMessage = customMessage
        else:
            compiledMessage = actionName + ': ' + str(state)

        # Log the message.
        targetFunction(compiledMessage)

    def constructScrapingList(self, start_date, end_date, query, body, partition):
        """
        This method will take four input parameters that will help construct URLs to be scraped
        
        Args:
        ---------------------
            start_date: Start date to get docs, format dd/MM/YYYY Ex: 7/10/2025 or 13/10/2025
            end_date: End date to get docs, format dd/MM/YYYY Ex: 7/10/2025 or 13/10/2025
            query: Query used to search for documents
            body: Selections available in workplacerelations, provided as keywords mapped to ids
                - Employment Appeals Tribunal: 2
                - Equality Tribunal: 1
                - Labour Count: 3
                - Workplace Relations Commission: 15376
                Multiple Keywords can be provided at a time separated by a comma
            partition: Select partitioning of dates in days, Ex: 1 for 1 day, 7 for a week, 30 for a month
        Returns:
        ---------------------
            Urls: list of urls constructed dynamically to be used to scrape data
        """
        self.logAction('info', 'Construct Urls', 'Starting.')
        baseURL = "https://www.workplacerelations.ie/en/search/?decisions=1"
        urls = []
        date_format = "%d/%m/%Y"
        oneDayparition = timedelta(days=1)
        partitionCount = 0

        # Separate provided body sequence
        input_list = body.split(',')
        self.logAction('info', 'Construct Urls', 'Query: ' + str(query) )
        self.logAction('info', 'Construct Urls', 'Body: ' + str(body) )
        self.logAction('info', 'Construct Urls', 'Start Date: ' + str(start_date) )
        self.logAction('info', 'Construct Urls', 'End Date: ' + str(end_date) )
        self.logAction('info', 'Construct Urls', 'Partition: ' + str(partition) + ' days')

        # Map each item in body to its corresponding ID
        mapped_values = [str(self.bodyMap[key]) for key in input_list if key in self.bodyMap.keys()]

        # Join Ids into one string
        bodyIds = ','.join(mapped_values)

        # transform dates for arithemtic reasons
        try:
            arithmeticStartDate = datetime.strptime(start_date, date_format).date()
            arithmeticEndDate = datetime.strptime(end_date, date_format).date()
        except Exception as e:
            self.logAction('error', 'Construct Urls', 'Provided Dates do not Follow Expected Format.')
            return e
        
        # Ensure parition is an integer and start date is not greater than end date 
        try:
            partition = int(partition)
            if partition <= 0:
                self.logAction('error', 'Construct Urls', 'Provided Partition is not an Integer.')
                raise InvalidObjectType('The partition provide is not an integer, kindly provide it in days (1,2,3,4,5)')
            else:
                partitionSteps = timedelta(days=partition)
            if arithmeticStartDate >= arithmeticEndDate:
                self.logAction('error', 'Construct Urls', 'Start Date is Greater than End Date.')
                raise ValueError('The Start Date Provided is Greater than the End Date Provided.')

        except Exception as e:
            return e
        
        # Initialize initial start date
        currentStartDate = arithmeticStartDate

        # While the start date is less than the end date
        while currentStartDate < arithmeticEndDate:
            partitionCount += 1
            # Get current end date based on start date and parition step (days)
            currentEndDate = currentStartDate + partitionSteps
            # If we exceeded the end date provide by user, reset to user end date
            if currentEndDate > arithmeticEndDate:
                currentEndDate = arithmeticEndDate

            # Format to expected format
            formattedStartDate = currentStartDate.strftime(date_format)
            formattedEndDate = currentEndDate.strftime(date_format)
            # Construct url
            url = f"{baseURL}&q=%22{query}%22&from={formattedStartDate}&to={formattedEndDate}&body={bodyIds}"
            
            self.logAction('info', 'Construct Urls', 'URL ' + str(partitionCount) + ': ' + url)
            
            # Apped to Urls list
            urls.append(url)

            currentStartDate = currentEndDate + oneDayparition
        
        self.logAction('info', 'Construct Urls', f"Finished, {len(urls)} Urls will be used for scraping")

        return urls
        
     
    