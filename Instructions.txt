Prerequisites:
 1- Git
 2- Docker Desktop
 3- Python 3.11

Clone the repository:
 1- git clone https://github.com/0RayanDaou/ScraperAssessment.git
 2- cd ScraperAssessment

Check for:
 1- docker-compose.yaml
 2- Dockerfile
 3- requirements.txt
 4- scraper folder that contains the scrapy.cfg and scraper package

Build Docker Images and Start Infrastructure:
 1- docker-compose Build
 2- docker-compose up -d mongo minio

Run the scraper using below statement, which will initialize the MinIO and MongoDB for the transform.py - 1083 documents/items should be retrieved/scraped:

 - docker compose run --rm scraper scrapy crawl documents -a start_date=01/01/2025 -a end_date=14/12/2025 -a query=labour -a body="Labour Court,Workplace Relations Commission,Equality Tribunal,Employment Appeals Tribunal" -a partition=10

The above statement scrapes the https://www.workplacerelations.ie/ from 1st of January 2025 to 14th of December 2025. With query = labour and body all abd parition = 10 days

SetUp environment variables to pass to transform:
 1- $env:TRANSFORM_START_DATE="YYYY-MM-dd"
 2- $env:TRANSFORM_END_DATE="YYYY-MM-dd"

Run Transform:
 - docker compose run --rm transform

To Verify results, check files at:
 - http://localhost:9001
 - landing bucket -> raw files
 - staging bucket -> transformed files

To Verify results, check metadata by:
 1- docker exec -it documents_mongo mongosh
 2- use WorkplaceRelation_metadata
 3- db.lnd_documents_metadata.countDocuments() -> returns total number
    db.lnd_documents_metadata.find().limit(5).pretty() -> returns 5 items 
    
    db.stg_documents_metadata.countDocuments() -> returns total number
    db.stg_documents_metadata.find().limit(5).pretty() -> returns 5 items 
 4- exit()

Stop everything by:
 - docker-compose down -v ( deletes everything)